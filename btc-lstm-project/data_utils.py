import pandas as pd
import numpy as np
import yfinance as yf
from fredapi import Fred
import requests
import joblib
import os
import time
from datetime import datetime
import streamlit as st

# ---------------------------------------------------------
# ì„¤ì • ë° ìƒìˆ˜
# ---------------------------------------------------------
# FRED API í‚¤ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©, í•„ìš”ì‹œ ë³¸ì¸ í‚¤ë¡œ ìˆ˜ì •)
FRED_API_KEY = os.getenv('FRED_API_KEY', '33f21fe5eacad6f3c9e71ca9ed7d0e1a')
START_DATE = '2017-01-01'

# í•™ìŠµ/ì˜ˆì¸¡ì—ì„œ ì‚¬ìš©í•  ìµœì¢… ë³€ìˆ˜ ëª©ë¡ (13ê°œ)
FEATURE_COLUMNS = [
    'BTC_Close', 'BTC_Volume', 'ETH_Close',   # ì‹œì¥ í™œë™ì„±
    'US_M2', 'US_CPI', 'US_10Y', 'Nasdaq',    # ê±°ì‹œê²½ì œ
    'DXY', 'Gold',                            # ëŒ€ì²´/ì•ˆì „ ìì‚°
    'Fear_Greed_Index', 'VIX', 'RSI', 'MACD'  # ì‹¬ë¦¬ ë° ê¸°ìˆ ì  ì§€í‘œ
]

# app.pyì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ TICKERS ë”•ì…”ë„ˆë¦¬ ì •ì˜
TICKERS = {col: col for col in FEATURE_COLUMNS}

# ---------------------------------------------------------
# 1. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ë“¤
# ---------------------------------------------------------
def fetch_binance_price(symbol, name):
    """ë°”ì´ë‚¸ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
    print(f"Fetching Binance {name}...")
    url = "https://api.binance.com/api/v3/klines"
    start_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)
    end_ts = int(datetime.now().timestamp() * 1000)
    
    all_data = []
    current = start_ts
    
    while current < end_ts:
        params = {'symbol': symbol, 'interval': '1d', 'startTime': current, 'limit': 1000}
        try:
            resp = requests.get(url, params=params, timeout=10).json()
            if not resp or isinstance(resp, dict): break
            all_data.extend(resp)
            current = resp[-1][0] + 1
            time.sleep(0.05)
        except: break
    
    if not all_data:
        print(f"âš ï¸ {name} ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    columns = [
        'Open time', 'Open', 'High', 'Low', 'Close', 'Volume',
        'Close time', 'Quote asset volume', 'Number of trades',
        'Taker buy base asset volume', 'Taker buy quote asset volume', 'Ignore'
    ]
    
    df = pd.DataFrame(all_data, columns=columns)
    df = df[['Open time', 'Close', 'Volume']]
    df.columns = ['Date', 'Close', 'Volume']
    
    df['Date'] = pd.to_datetime(df['Date'], unit='ms').dt.normalize()
    df.set_index('Date', inplace=True)
    
    cols = ['Close', 'Volume'] if name == 'BTC' else ['Close']
    for c in cols:
        df[c] = pd.to_numeric(df[c], errors='coerce')
        
    df = df[cols]
    df.columns = [f"{name}_{c}" for c in df.columns]
    return df

def fetch_macro():
    """Yahoo Finance ê±°ì‹œê²½ì œ ì§€í‘œ"""
    print("Fetching Macro Data...")
    tickers = {
        '^NDX': 'Nasdaq', 'DX-Y.NYB': 'DXY', 'GC=F': 'Gold', 
        '^TNX': 'US_10Y', '^VIX': 'VIX'
    }
    try:
        df = yf.download(list(tickers.keys()), start=START_DATE, progress=False)['Close']
        if isinstance(df.columns, pd.MultiIndex): 
            df.columns = [col[0] if isinstance(col, tuple) else col for col in df.columns]
        
        df.rename(columns=tickers, inplace=True)
        df.index = df.index.normalize()
        return df
    except Exception as e:
        print(f"âš ï¸ Yahoo Finance Error: {e}")
        return pd.DataFrame()

def fetch_fred():
    """FRED (CPI, M2)"""
    print("Fetching FRED Data...")
    try:
        fred = Fred(api_key=FRED_API_KEY)
        cpi = fred.get_series('CPIAUCSL', observation_start=START_DATE)
        m2 = fred.get_series('M2SL', observation_start=START_DATE)
        df = pd.DataFrame({'US_CPI': cpi, 'US_M2': m2})
        df.index = pd.to_datetime(df.index).normalize()
        return df.resample('D').ffill()
    except Exception as e:
        print(f"âš ï¸ FRED API Error: {e}")
        return pd.DataFrame()

def fetch_sentiment():
    """Fear & Greed Index"""
    print("Fetching Sentiment...")
    try:
        url = "https://api.alternative.me/fng/?limit=0&format=json"
        data = requests.get(url).json()['data']
        df = pd.DataFrame(data)
        df['Date'] = pd.to_datetime(df['timestamp'].astype(int), unit='s').dt.normalize()
        df.set_index('Date', inplace=True)
        df.sort_index(inplace=True)
        s = pd.to_numeric(df['value'])
        s.name = 'Fear_Greed_Index'
        return s
    except Exception as e:
        print(f"âš ï¸ Sentiment Error: {e}")
        return pd.Series(dtype=float)

# ---------------------------------------------------------
# 2. ë©”ì¸ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
# ---------------------------------------------------------
@st.cache_data(ttl=3600)  # Streamlit ìºì‹± ì ìš©
def fetch_multi_data():
    """ëª¨ë“  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  13ê°œ ë³€ìˆ˜ë¡œ ì •ë¦¬í•˜ì—¬ ë°˜í™˜"""
    print("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ ì‹œì‘...")
    
    # 1. ìˆ˜ì§‘
    btc = fetch_binance_price('BTCUSDT', 'BTC')
    eth = fetch_binance_price('ETHUSDT', 'ETH')
    macro = fetch_macro()
    econ = fetch_fred()
    sent = fetch_sentiment()
    
    # 2. ë³‘í•©
    df = btc.join([eth, macro, econ, sent], how='outer').sort_index()
    df.fillna(method='ffill', inplace=True)
    df.dropna(inplace=True)
    
    # 3. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (RSI, MACD)
    close = df['BTC_Close']
    
    # RSI
    delta = close.diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    
    # MACD
    ema12 = close.ewm(span=12, adjust=False).mean()
    ema26 = close.ewm(span=26, adjust=False).mean()
    df['MACD'] = ema12 - ema26
    
    # 4. ìµœì¢… ì»¬ëŸ¼ í•„í„°ë§ (13ê°œ)
    available_cols = [c for c in FEATURE_COLUMNS if c in df.columns]
    df = df[available_cols].dropna()
    
    # [ì¤‘ìš”] app.py ì‹œê°í™”ë¥¼ ìœ„í•´ timestamp ì»¬ëŸ¼ ìƒì„± (index -> column)
    # reset_index()ë¥¼ í•˜ë©´ index ì´ë¦„ì´ ì»¬ëŸ¼ìœ¼ë¡œ ë“¤ì–´ì˜´
    df_reset = df.reset_index()
    
    # ì»¬ëŸ¼ëª… í†µì¼ (Date ë˜ëŠ” index -> timestamp)
    if 'Date' in df_reset.columns:
        df_reset.rename(columns={'Date': 'timestamp'}, inplace=True)
    elif 'index' in df_reset.columns:
        df_reset.rename(columns={'index': 'timestamp'}, inplace=True)
        
    return df_reset

# ---------------------------------------------------------
# 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (í•™ìŠµ/ì•± ê³µìš©)
# ---------------------------------------------------------
def load_scaler(path='weights/scaler.pkl'):
    """ì €ì¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±"""
    # Streamlit Cloud ê²½ë¡œ í˜¸í™˜ì„±
    base_dir = os.path.dirname(os.path.abspath(__file__))
    full_path = os.path.join(base_dir, path)
    
    if os.path.exists(full_path):
        return joblib.load(full_path)
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ í•™ìŠµí•´ì„œ ë°˜í™˜ (ì•± ì—ëŸ¬ ë°©ì§€)
    from sklearn.preprocessing import StandardScaler
    df = fetch_multi_data()
    feature_data = df[FEATURE_COLUMNS]
    scaler = StandardScaler()
    scaler.fit(feature_data)
    
    # weights í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„± í›„ ì €ì¥
    os.makedirs(os.path.dirname(full_path), exist_ok=True)
    joblib.dump(scaler, full_path)
    
    return scaler
