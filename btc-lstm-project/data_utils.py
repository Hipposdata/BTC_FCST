import pandas as pd
import numpy as np
import yfinance as yf
from fredapi import Fred
import requests
import joblib
import os
import time
from datetime import datetime

# ---------------------------------------------------------
# ì„¤ì • ë° ìƒìˆ˜
# ---------------------------------------------------------
FRED_API_KEY = os.getenv('FRED_API_KEY', '33f21fe5eacad6f3c9e71ca9ed7d0e1a')
START_DATE = '2017-01-01'

# í•™ìŠµ/ì˜ˆì¸¡ì—ì„œ ì‚¬ìš©í•  ìµœì¢… ë³€ìˆ˜ ëª©ë¡
FEATURE_COLUMNS = [
    'BTC_Close', 'BTC_Volume', 'ETH_Close',   # ì‹œì¥ í™œë™ì„±
    'US_M2', 'US_CPI', 'US_10Y', 'Nasdaq',    # ê±°ì‹œê²½ì œ
    'DXY', 'Gold',                            # ëŒ€ì²´/ì•ˆì „ ìì‚°
    'Fear_Greed_Index', 'VIX', 'RSI', 'MACD'  # ì‹¬ë¦¬ ë° ê¸°ìˆ ì  ì§€í‘œ
]

# train.py í˜¸í™˜ì„±ì„ ìœ„í•œ TICKERS ë”•ì…”ë„ˆë¦¬
TICKERS = {col: col for col in FEATURE_COLUMNS}

# ---------------------------------------------------------
# 1. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ë“¤
# ---------------------------------------------------------
def fetch_binance_price(symbol, name):
    """ë°”ì´ë‚¸ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
    print(f"  Fetching Binance {name}...")
    url = "https://api.binance.com/api/v3/klines"
    start_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)
    end_ts = int(datetime.now().timestamp() * 1000)
    
    all_data = []
    current = start_ts
    
    while current < end_ts:
        params = {'symbol': symbol, 'interval': '1d', 'startTime': current, 'limit': 1000}
        try:
            resp = requests.get(url, params=params, timeout=10).json()
            if not resp or isinstance(resp, dict): break
            all_data.extend(resp)
            current = resp[-1][0] + 1
            time.sleep(0.05)
        except: break
    
    # [ìˆ˜ì •] Binance APIëŠ” ì •í™•íˆ 12ê°œì˜ ì»¬ëŸ¼ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    columns = [
        'Open time', 'Open', 'High', 'Low', 'Close', 'Volume',
        'Close time', 'Quote asset volume', 'Number of trades',
        'Taker buy base asset volume', 'Taker buy quote asset volume', 'Ignore'
    ]
    
    # ë°ì´í„°ê°€ ë¹„ì–´ìˆì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
    if not all_data:
        print(f"âš ï¸ {name} ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    df = pd.DataFrame(all_data, columns=columns)
    
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ ë° ì •ë¦¬
    df = df[['Open time', 'Close', 'Volume']]
    df.columns = ['Date', 'Close', 'Volume']
    
    # ë‚ ì§œ ë³€í™˜
    df['Date'] = pd.to_datetime(df['Date'], unit='ms').dt.normalize()
    df.set_index('Date', inplace=True)
    
    # ìˆ«ì ë³€í™˜
    cols = ['Close', 'Volume'] if name == 'BTC' else ['Close']
    for c in cols:
        df[c] = pd.to_numeric(df[c], errors='coerce')
        
    df = df[cols]
    df.columns = [f"{name}_{c}" for c in df.columns]
    return df

def fetch_macro():
    """Yahoo Finance ê±°ì‹œê²½ì œ ì§€í‘œ"""
    print("  Fetching Macro Data...")
    tickers = {
        '^NDX': 'Nasdaq', 'DX-Y.NYB': 'DXY', 'GC=F': 'Gold', 
        '^TNX': 'US_10Y', '^VIX': 'VIX'
    }
    try:
        df = yf.download(list(tickers.keys()), start=START_DATE, progress=False)['Close']
        if isinstance(df.columns, pd.MultiIndex): 
            df.columns = [col[0] if isinstance(col, tuple) else col for col in df.columns]
        
        df.rename(columns=tickers, inplace=True)
        df.index = df.index.normalize()
        return df
    except Exception as e:
        print(f"âš ï¸ Yahoo Finance Error: {e}")
        return pd.DataFrame()

def fetch_fred():
    """FRED (CPI, M2)"""
    print("  Fetching FRED Data...")
    try:
        fred = Fred(api_key=FRED_API_KEY)
        cpi = fred.get_series('CPIAUCSL', observation_start=START_DATE)
        m2 = fred.get_series('M2SL', observation_start=START_DATE)
        df = pd.DataFrame({'US_CPI': cpi, 'US_M2': m2})
        df.index = pd.to_datetime(df.index).normalize()
        return df.resample('D').ffill()
    except Exception as e:
        print(f"âš ï¸ FRED API Error: {e}")
        return pd.DataFrame()

def fetch_sentiment():
    """Fear & Greed Index"""
    print("  Fetching Sentiment...")
    try:
        url = "https://api.alternative.me/fng/?limit=0&format=json"
        data = requests.get(url).json()['data']
        df = pd.DataFrame(data)
        df['Date'] = pd.to_datetime(df['timestamp'].astype(int), unit='s').dt.normalize()
        df.set_index('Date', inplace=True)
        df.sort_index(inplace=True)
        s = pd.to_numeric(df['value'])
        s.name = 'Fear_Greed_Index'
        return s
    except Exception as e:
        print(f"âš ï¸ Sentiment Error: {e}")
        return pd.Series()

# ---------------------------------------------------------
# 2. ë©”ì¸ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (fetch_multi_data)
# ---------------------------------------------------------
def fetch_multi_data():
    """ëª¨ë“  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  13ê°œ ë³€ìˆ˜ë¡œ ì •ë¦¬í•˜ì—¬ ë°˜í™˜"""
    print("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ ì‹œì‘...")
    
    # 1. ìˆ˜ì§‘
    btc = fetch_binance_price('BTCUSDT', 'BTC')
    eth = fetch_binance_price('ETHUSDT', 'ETH')
    macro = fetch_macro()
    econ = fetch_fred()
    sent = fetch_sentiment()
    
    # 2. ë³‘í•©
    df = btc.join([eth, macro, econ, sent], how='outer').sort_index()
    df.fillna(method='ffill', inplace=True)
    df.dropna(inplace=True)
    
    # 3. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (RSI, MACD)
    close = df['BTC_Close']
    
    # RSI
    delta = close.diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    
    # MACD
    ema12 = close.ewm(span=12, adjust=False).mean()
    ema26 = close.ewm(span=26, adjust=False).mean()
    df['MACD'] = ema12 - ema26
    
    # 4. ìµœì¢… ì»¬ëŸ¼ í•„í„°ë§ (13ê°œ)
    # ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ í›„ ì„ íƒ
    available_cols = [c for c in FEATURE_COLUMNS if c in df.columns]
    df = df[available_cols].dropna()
    
    return df.reset_index().rename(columns={'Date': 'timestamp', 'index': 'timestamp'})

# ---------------------------------------------------------
# 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (í•™ìŠµìš©)
# ---------------------------------------------------------
def create_sequences(data, seq_length, prediction_days=7, target_col_idx=0):
    xs, ys = [], []
    for i in range(len(data) - seq_length - prediction_days + 1):
        x = data[i:(i + seq_length)]
        y = data[i + seq_length : i + seq_length + prediction_days, target_col_idx]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

def save_scaler(scaler, path='weights/scaler.pkl'):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    joblib.dump(scaler, path)

def load_scaler(path='weights/scaler.pkl'):
    base_path = os.path.dirname(os.path.abspath(__file__))
    full_path = os.path.join(base_path, path)
    if not os.path.exists(full_path):
        if os.path.exists(path): full_path = path
        else: raise FileNotFoundError(f"ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {full_path}")
    return joblib.load(full_path)
